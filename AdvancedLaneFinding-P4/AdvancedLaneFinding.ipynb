{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pimg\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Camera Calibration\n",
    "#Takes in List of chessboard Images taken from your camera\n",
    "#and calculates its calibration and returns camera matrix, distortion coefficients\n",
    "#in below function we are looking at chess board images of 6 * 9\n",
    "def calibrateCameraWithImages(Images):\n",
    "    \n",
    "    obj_points = []\n",
    "    img_points = []\n",
    "\n",
    "    objp = np.zeros((6 * 9, 3),np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) #x ,y\n",
    "\n",
    "    for image in Images:\n",
    "        img = pimg.imread(image)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        ret,corners = cv2.findChessboardCorners(gray,(9,6),None)\n",
    "        if ret == True:\n",
    "            img_points.append(corners)\n",
    "            obj_points.append(objp)\n",
    "            cv2.drawChessboardCorners(img,(9,6),corners,ret)\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs =  cv2.calibrateCamera(obj_points,img_points,img.shape[0:2],None,None)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Returns an undistored Image given a camera image, camera matrix, distortion coefficients\n",
    "def cal_undistort(img, mtx, dist):    \n",
    "    undist = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#vizualize a sample camera image and its undistored image\n",
    "def viz_camera_calib(mtx, dist):\n",
    "    input_image = pimg.imread(\"data/camera_cal/calibration1.jpg\")\n",
    "    undistorted = cal_undistort(input_image, mtx, dist)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(input_image)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(undistorted)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Sobel Gradient Filtering\n",
    "# Takes in arguments for orient(x-axis / y-axis), threshold values to filter, kernel size and color channel to work on\n",
    "#you can choose to work on GRAY image or convert to HLS channel and choose S channel Image\n",
    "def sobel_thres(src,orient = 'x',thres = (50,120),color_channel='GRAY',kernel=3):\n",
    "    \n",
    "    if color_channel == 'GRAY':\n",
    "        gray = cv2.cvtColor(src,cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        hls = cv2.cvtColor(src,cv2.COLOR_RGB2HLS)\n",
    "        gray = hls[:,:,2]\n",
    "    sobel = cv2.Sobel(gray,cv2.CV_64F,orient == 'x',orient == 'y',ksize=kernel)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_scaled = np.uint8(sobel_abs * 255 / np.max(sobel_abs))\n",
    "    sobel_binary = np.zeros_like(sobel_scaled)\n",
    "    sobel_binary[(sobel_scaled >= thres[0]) & (sobel_scaled <= thres[1])] = 1\n",
    "    return sobel_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Sobel Gradient filtering on combined x and y axis\n",
    "# combines X and Y axis sobel gradients and then perfomrs threshold filtering\n",
    "def sobel_thres_magnitude(src,thres = (50,120),color_channle='GRAY',kernel=3):   \n",
    "    if color_channle == 'GRAY':\n",
    "        gray = cv2.cvtColor(src,cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        hls = cv2.cvtColor(src,cv2.COLOR_RGB2HLS)\n",
    "        gray = hls[:,:,2]\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    sobel_mag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    sobel_scaled = np.uint8(sobel_mag * 255 / np.max(sobel_mag))\n",
    "    sobel_binary = np.zeros_like(sobel_scaled)\n",
    "    sobel_binary[(sobel_scaled >= thres[0]) & (sobel_scaled <= thres[1])] = 1\n",
    "    return sobel_binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Converts given image to HLS channel \n",
    "#chooses the channel passed and performs color filtering on threshold values passed\n",
    "def color_spaces(src,color_space = 'S',thres=(150,255)):\n",
    "    hls = cv2.cvtColor(src,cv2.COLOR_RGB2HLS)\n",
    "    if color_space == 'H':\n",
    "        i = 0\n",
    "    elif color_space == 'L':\n",
    "        i = 1\n",
    "    else:\n",
    "        i = 2\n",
    "    sub_img = hls[:,:,i]\n",
    "    color_binary = np.zeros_like(sub_img)\n",
    "    color_binary[(sub_img > thres[0]) & (sub_img <= thres[1])] = 1\n",
    "    return color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sobel_thres_gray(src):\n",
    "    sobel = cv2.Sobel(src,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_scaled = np.uint8(sobel_abs * 255 / np.max(sobel_abs))\n",
    "    return sobel_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converts given image to given color space channel \n",
    "#chooses the channel passed and performs color filtering on threshold values passed\n",
    "def color_spaces(src,color_space = 'RGB',thres=(150,255)):\n",
    "\n",
    "    if color_space == 'HLS':\n",
    "        i = 0  \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2HLS)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    elif color_space == 'YUV':\n",
    "        i = 2\n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2YUV)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    elif color_space == 'LUV':\n",
    "        i = 0 \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2LUV)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "        sub_img = sobel_thres_gray(sub_img)\n",
    "    elif color_space == 'LAB':\n",
    "        i = 2 \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2LAB)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    else:\n",
    "        i = 0\n",
    "        color_channel = cv2.cvtColor(src,channel)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "        sub_img = sobel_thres_gray(sub_img)\n",
    "\n",
    "\n",
    "    output_image = np.zeros_like(sub_img)\n",
    "    output_image[(sub_img > thres[0]) & (sub_img <= thres[1])] = 1\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for a given image, it returns the image with only region of interest displayed\n",
    "# for viszualization purpose\n",
    "def region_of_interest(image):\n",
    "    img_height = image.shape[0]\n",
    "    img_width = image.shape[1]\n",
    "    vertices = np.array([[(np.int(img_width * 0.10 ),np.int(img_height * 0.93)),\n",
    "                    (np.int(img_width * 0.40 ),np.int(img_height * 0.65 )),\n",
    "                    (np.int(img_width * 0.60 ),np.int(img_height * 0.65 )),\n",
    "                    (np.int(img_width * 0.90 ),np.int(img_height * 0.93))]],dtype=np.int32)\n",
    "    mask = np.zeros_like(image)       \n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)   \n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for a given image, it identifies the region of interest and transforms its perspective to birds-eye view\n",
    "# this will avoid front view distortion issues of lane lines\n",
    "# the function also returns Minv to get back the original image if needed later\n",
    "def perspective_transoform(image):\n",
    "    img_height = image.shape[0]\n",
    "    img_width = image.shape[1]\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    #print(image.shape)\n",
    "    offset = np.int(img_height * 0.075)\n",
    "    src = np.float32([[np.int(img_width * 0.10 ),np.int(img_height * 0.97)],\n",
    "                    [np.int(img_width * 0.40 ),np.int(img_height * 0.65 )],\n",
    "                    [np.int(img_width * 0.60 ),np.int(img_height * 0.65 )],\n",
    "                    [ np.int(img_width * 0.90 ),np.int(img_height * 0.97)]])\n",
    "    dst = np.float32([ [offset, img_size[1]-offset],[offset, offset], [img_size[0]-offset, offset],\n",
    "                                     [img_size[0]-offset, img_size[1]-offset]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(image, M, img_size)\n",
    "    return warped,Minv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Identifies white color in Region of Interest of the input frame.\n",
    "#Expectation is to identify white lane lines\n",
    "def white_filter(image,thres=200):\n",
    "    \n",
    "    color_threshold = [thres, thres, thres]\n",
    "    color_filter = (image[:,:,0] < color_threshold[0]) | (image[:,:,1] < color_threshold[1]) | (image[:,:,2] < color_threshold[2])\n",
    "    white = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    white[color_filter] = 0\n",
    "    white[~color_filter] = 1\n",
    "    return region_of_interest(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies Sobel gradient in X-axis direction for a given single color image\n",
    "def sobel_thres_gray(src):\n",
    "    sobel = cv2.Sobel(src,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_scaled = np.uint8(sobel_abs * 255 / np.max(sobel_abs))\n",
    "    return sobel_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converts given image to given color space channel \n",
    "#chooses the channel passed and performs color filtering on threshold values passed\n",
    "def color_spaces(src,color_space = 'RGB',thres=(150,255)):\n",
    "\n",
    "    if color_space == 'HLS':\n",
    "        i = 2  \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2HLS)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    elif color_space == 'YUV':\n",
    "        i = 2\n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2YUV)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    elif color_space == 'LUV':\n",
    "        i = 0 \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2LUV)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "        sub_img = sobel_thres_gray(sub_img)\n",
    "    elif color_space == 'LAB':\n",
    "        i = 2 \n",
    "        color_channel = cv2.cvtColor(src,cv2.COLOR_RGB2LAB)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "    else:\n",
    "        i = 0\n",
    "        color_channel = cv2.cvtColor(src,channel)\n",
    "        sub_img = color_channel[:,:,i]\n",
    "        sub_img = sobel_thres_gray(sub_img)\n",
    "\n",
    "\n",
    "    output_image = np.zeros_like(sub_img)\n",
    "    output_image[(sub_img > thres[0]) & (sub_img <= thres[1])] = 1\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this function defines the pipeline used to binary image\n",
    "# For a given image, this function performs various color and gradient thresholdings\n",
    "#combines them in meaningful way and returns final Binary image used to identify lane lines\n",
    "#Data Pipeline\n",
    "    #calculate Sobel Gradient for X-axis, Y-axis, X and Y Magnitude on Gray Image\n",
    "    #calculate Sobel Gradient for X-axis, Y-axis, X and Y Magnitude on S channel Image of HLS\n",
    "    #get color thresholding filtered image of S channel\n",
    "    #Img1 : Gray Scale X-axis and Y-axis combined\n",
    "    #Img2 : S channel X-axis and Y-axis combined\n",
    "    #Img3 : Color Channel and Gray Magnitude combined\n",
    "    #Img4 : Color Channel and S channel Magnitude combined  \n",
    "    #Final Binary Image: OR combination of (Img1,Img2,Img3,Img4) \n",
    "    \n",
    "def all_combinations(src,grad_thres=(50,120),color_thres=(50,255),kernel=9):\n",
    "    sobelx_gray = sobel_thres(src,'x',grad_thres,'GRAY',kernel)\n",
    "    sobely_gray = sobel_thres(src,'y',grad_thres,'GRAY',kernel)\n",
    "    sobel_mag_gray = sobel_thres_magnitude(src,grad_thres,'GRAY',kernel)\n",
    "    sobelx_S = sobel_thres(src,'x',grad_thres,'S',kernel)\n",
    "    sobely_S = sobel_thres(src,'y',grad_thres,'S',kernel)\n",
    "    sobel_mag_S = sobel_thres_magnitude(src,grad_thres,'S',kernel)\n",
    "    color_channel = color_spaces(src,'HLS',color_thres)\n",
    "    color_yuv = region_of_interest(color_spaces(src,'YUV',(0,110)))  # Identify Yellow color\n",
    "    color_lab = region_of_interest(color_spaces(src,'LAB',(150,255))) # Identify Yellow color\n",
    "    color_white = white_filter(src) #Identify White color\n",
    "    \n",
    "\n",
    "    yellow = np.zeros_like(sobelx_gray)\n",
    "    yellow_white = np.zeros_like(sobelx_gray)\n",
    "    combined_binary = np.zeros_like(sobelx_gray)\n",
    "    final_image = np.zeros_like(sobelx_gray)\n",
    "    \n",
    "    yellow[((color_yuv == 1) & (color_lab == 1))] = 1\n",
    "    yellow_white[((color_white == 1) | (yellow == 1))] = 1\n",
    "    \n",
    "    combined_binary[((sobelx_gray == 1) & (sobely_gray == 1)) | \n",
    "                    ((sobelx_S == 1) & (sobely_S == 1)) | \n",
    "                    ((sobel_mag_S == 1) & (color_channel == 1)) |\n",
    "                    ((sobel_mag_gray == 1) & (color_channel == 1))] = 1\n",
    "    \n",
    "    combined_binary = region_of_interest(combined_binary)\n",
    "    final_image[(combined_binary == 1) | (yellow_white == 1)] = 1\n",
    "    \n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#vizualize each step of pipeline\n",
    "#Optional\n",
    "def visualize_pipeline(src,grad_thres=(50,120),color_thres=(50,255),kernel=9):\n",
    "    \n",
    "\n",
    "    sobelx_gray = sobel_thres(src,'x',grad_thres,'GRAY',kernel)\n",
    "    sobely_gray = sobel_thres(src,'y',grad_thres,'GRAY',kernel)\n",
    "    sobel_mag_gray = sobel_thres_magnitude(src,grad_thres,'GRAY',kernel)\n",
    "    sobelx_S = sobel_thres(src,'x',grad_thres,'S',kernel)\n",
    "    sobely_S = sobel_thres(src,'y',grad_thres,'S',kernel)\n",
    "    sobel_mag_S = sobel_thres_magnitude(src,grad_thres,'S',kernel)\n",
    "    color_channel = color_spaces(src,'S',color_thres)\n",
    "    combined_binary = all_combinations(src,grad_thres,color_thres,kernel)\n",
    "    \n",
    "    pic_region = region_of_interest(src)\n",
    "    pic_warped, p_Minv = perspective_transoform(src)\n",
    "    binary_warped, Minv = perspective_transoform(combined_binary)\n",
    "    \n",
    "    # Plot the result\n",
    "    f, ((ax1, ax2, ax3), (ax4, ax5, ax6),(ax7, ax8, ax9),(ax10, ax11, ax12)) = plt.subplots(4, 3, figsize=(25, 25),sharex='col', sharey='row')\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(src)\n",
    "    ax1.set_title('Original Image', fontsize=15)\n",
    "    ax2.imshow(sobelx_gray, cmap='gray')\n",
    "    ax2.set_title('X axis: Thresholded Gradient Gray Channel', fontsize=15)\n",
    "    ax3.imshow(sobely_gray, cmap='gray')\n",
    "    ax3.set_title('Y axis: Thresholded Gradient Gray Channel', fontsize=15)\n",
    "    ax4.imshow(sobel_mag_gray, cmap='gray')\n",
    "    ax4.set_title('combined: Thresholded Gradient Gray Channel', fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "    ax5.imshow(sobelx_S, cmap='gray')\n",
    "    ax5.set_title('X axis: Thresholded Gradient S Channel', fontsize=15)\n",
    "    ax6.imshow(sobely_S, cmap='gray')\n",
    "    ax6.set_title('Y axis: Thresholded Gradient S Channel', fontsize=15)\n",
    "    ax7.imshow(sobel_mag_S, cmap='gray')\n",
    "    ax7.set_title('combined: Thresholded Gradient S Channel', fontsize=15)\n",
    "\n",
    "    ax8.imshow(color_channel, cmap='gray')\n",
    "    ax8.set_title('Color Channel S', fontsize=15)\n",
    "    ax9.imshow(combined_binary, cmap='gray')\n",
    "    ax9.set_title('Combined', fontsize=15)\n",
    "    \n",
    "    ax10.imshow(pic_region)\n",
    "    ax10.set_title('Region of Interest', fontsize=15)\n",
    "    ax11.imshow(pic_warped)\n",
    "    ax11.set_title('Perspective Transform: ROI', fontsize=15)\n",
    "    ax12.imshow(binary_warped, cmap='gray')\n",
    "    ax12.set_title('Perspective Transform: Binary Image', fontsize=15)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#For given Binary image,Returns X axis and y axis Pixel positions of left line and right line\n",
    "# uses Sliding window approach\n",
    "def get_pixelpositions_withSlidigWindow(binary_warped):\n",
    "    \n",
    "    histogram = np.sum(binary_warped[np.int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])   # base position of left lane line\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint # base position of right lane line\n",
    "    \n",
    "    #assigning values to x and y meter convertion global variables\n",
    "    # need assignment only in first run and values will be constant throught the video processing\n",
    "    global ym_per_pix\n",
    "    global xm_per_pix\n",
    "    \n",
    "    ym_per_pix = 30/binary_warped.shape[0] if ym_per_pix is None else ym_per_pix # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/(rightx_base -leftx_base) if xm_per_pix is None else xm_per_pix # meters per pixel in x dimension \n",
    "\n",
    "    nwindows = 9\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    margin = np.int(binary_warped.shape[1] * 0.075)  # margin to check\n",
    "    minpix =  np.int(binary_warped.shape[0] * 0.05) # min points\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    return leftx,lefty,rightx,righty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given image, polymonial fit coefficients of previous left and right lane\n",
    "#identifies the current image x and y values of left and right lane\n",
    "#Assumption  is that, Lane Lines will not change its position significantly from last frame\n",
    "def get_pixelpositions_withPreviousLinefits(binary_warped,left_fitx,right_fitx):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = np.int(binary_warped.shape[1] * 0.075)  # margin with in which to check for lane lines instead of whole image\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fit = np.polyfit(ploty, left_fitx, 2)\n",
    "    right_fit = np.polyfit(ploty, right_fitx, 2)\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    return leftx,lefty,rightx,righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Visualization of sliding window\n",
    "\n",
    "def viz_sliding_windows(nonzeroy,nonzerox,left_lane_inds,right_lane_inds):\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [255, 0, 0]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, binary_warped.shape[1])\n",
    "    plt.ylim(binary_warped.shape[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Curvature Calculation\n",
    "#Returns strings to be printed on output Image\n",
    "#curvature radious and position offset\n",
    "\n",
    "def get_curve_offset(binary_warped,lefty,leftx,righty,rightx):\n",
    "\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    y_eval = np.max(ploty) # bottom of Image\n",
    "\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    \n",
    "    #car offset from center\n",
    "    # calculate Lane center, Image center in meters and do subraction\n",
    "    ybottom_in_meters = y_eval*ym_per_pix\n",
    "    left_bottomx = left_fit_cr[0]*ybottom_in_meters**2 + left_fit_cr[1]*ybottom_in_meters + left_fit_cr[2]\n",
    "    right_bottomx = right_fit_cr[0]*ybottom_in_meters**2 + right_fit_cr[1]*ybottom_in_meters + right_fit_cr[2]\n",
    "    lane_center = left_bottomx + (right_bottomx - left_bottomx) / 2\n",
    "    image_center = binary_warped.shape[1] * xm_per_pix / 2\n",
    "    offset = image_center - lane_center\n",
    "\n",
    "    #print(offset)\n",
    "    curve = \"Radius of Curvature = {:0.2f} (m)\".format(min(left_curverad,right_curverad))\n",
    "    direction = 'left of center' if offset < 0.0 else 'right of center' if offset > 0.0 else 'in the center'\n",
    "    position = 'Vehicle is {:0.2f}m '.format(np.absolute(offset)) +direction\n",
    "    return curve,position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Draws the final output image stitched in video\n",
    "#Takes input image, binary warped image, left and right lane x-axis positions\n",
    "#Minv for calculating back original image from warped image\n",
    "#curve and position strings to be printed on output image\n",
    "def draw_output_image(inputImage,binary_warped,left_fitx,right_fitx,Minv,curve,position):\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (binary_warped.shape[1], binary_warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(inputImage, 1, newwarp, 0.3, 0)\n",
    " \n",
    "    #put text string on output image\n",
    "    cv2.putText(result,curve,(100,50),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),2)\n",
    "    cv2.putText(result,position,(100,100),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),2)\n",
    "    #plt.imshow(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sanity Check\n",
    "# For currentline x-axis pixel positions, does basic sanity checks and returns boolean to accept or reject line\n",
    "def sanity_check(binary_warped,current_line,previous_line):\n",
    "    width = binary_warped.shape[1]\n",
    "    height = binary_warped.shape[0]\n",
    "    margin = np.int(width * 0.05)\n",
    "    top_diff = np.absolute(current_line[0] - previous_line[0])\n",
    "    bottom_diff = np.absolute(current_line[-1] - previous_line[-1])\n",
    "    middle_diff = np.absolute(current_line[np.int(height/2)] - previous_line[np.int(height/2)])\n",
    "    line_check_bottom = current_line[-1] >= 0.10 * width and current_line[-1] <= 0.95 * width\n",
    "    line_check_top = current_line[0] >= 0.10 * width and current_line[0] <= 0.95 * width\n",
    "    if(top_diff < margin and bottom_diff < margin and middle_diff < margin and line_check_bottom and line_check_top):\n",
    "        return True\n",
    "    else:\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Function that takes input image and return output image\n",
    "# contains entire pipeline of processing\n",
    "# 1. get undistorted image of input\n",
    "# 2. get final binary image with all color and gradient filtering\n",
    "# 3. get binary warped image using perspective transform\n",
    "# 4. get x and y axis pixel positions of left and right lanes from binary warped image\n",
    "# 5. calculate the polynomial fit coefficients of left and right lanes\n",
    "# 6. get the exact x and y axis pixel positions of left and right lane\n",
    "# 7. get the radius curvature and vehicle offset from center\n",
    "# 8. get the final output image\n",
    "\n",
    "def get_output_image(input_image):\n",
    "    src = cal_undistort(input_image, mtx, dist)\n",
    "    processed_binary_image = all_combinations(src,grad_thres,color_thres,kernel)\n",
    "\n",
    "    binary_warped, Minv = perspective_transoform(processed_binary_image)\n",
    "    \n",
    "    global previous_left_fitx\n",
    "    global previous_right_fitx\n",
    "    global previous_left_used_counter\n",
    "    global previous_right_used_counter\n",
    "    \n",
    "    SEARCH_FROM_SCRATH = False\n",
    "    \n",
    "    if len(previous_left_fitx) > 0 and  len(previous_right_fitx) > 0:\n",
    "        leftx,lefty,rightx,righty = get_pixelpositions_withPreviousLinefits(binary_warped,previous_left_fitx,previous_right_fitx)\n",
    "    else:   \n",
    "        leftx,lefty,rightx,righty = get_pixelpositions_withSlidigWindow(binary_warped)\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    accept_left = True\n",
    "    accept_right = True\n",
    "    \n",
    "    #Sanity Check\n",
    "    if len(previous_left_fitx) > 0:\n",
    "        temp_leftx = 0.6 * left_fitx + 0.4 * previous_left_fitx   #exponential Decay\n",
    "        accept_left = sanity_check(binary_warped,temp_leftx,previous_left_fitx)\n",
    "        if(accept_left):\n",
    "            use_leftx = temp_leftx\n",
    "            previous_left_used_counter = 0\n",
    "        else:\n",
    "            use_leftx = previous_left_fitx\n",
    "            previous_left_used_counter = previous_left_used_counter + 1\n",
    "            if(previous_left_used_counter > 7):\n",
    "                #print('Left Lane used Last ', previous_left_used_counter,' times')\n",
    "                SEARCH_FROM_SCRATH = True\n",
    "    else:\n",
    "        use_leftx = left_fitx\n",
    "        previous_left_used_counter = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "    if len(previous_right_fitx) > 0:    \n",
    "        temp_rightx = 0.6 * right_fitx + 0.4 * previous_right_fitx\n",
    "        accept_right = sanity_check(binary_warped,temp_rightx,previous_right_fitx)  \n",
    "        if(accept_right):\n",
    "            use_rightx = temp_rightx\n",
    "            previous_right_used_counter = 0\n",
    "        else:\n",
    "            use_rightx = previous_right_fitx\n",
    "            previous_right_used_counter = previous_right_used_counter + 1\n",
    "            if(previous_right_used_counter > 7):\n",
    "                #print('Right Lane used Last ', previous_right_used_counter,' times')\n",
    "                SEARCH_FROM_SCRATH = True\n",
    "    else:\n",
    "        use_rightx = right_fitx\n",
    "        previous_right_used_counter = 0\n",
    "        \n",
    "    curve,position = get_curve_offset(binary_warped,lefty,leftx,righty,rightx)\n",
    "    output_image = draw_output_image(src,binary_warped,left_fitx,right_fitx,Minv,curve,position)\n",
    "    \n",
    "    if SEARCH_FROM_SCRATH:\n",
    "        previous_left_fitx = []    # use Sliding Window next frame\n",
    "        previous_right_fitx = []   # use Sliding Window next frame\n",
    "    else: \n",
    "        previous_left_fitx = use_leftx     # use left fit in next frame\n",
    "        previous_right_fitx = use_rightx   # use right fit in next frame\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Main method starts here\n",
    "\n",
    "# Camera calibration step\n",
    "Images = glob.glob('data/camera_cal/calibration*.jpg')\n",
    "mtx, dist = calibrateCameraWithImages(Images)   \n",
    "\n",
    "#variables\n",
    "grad_thres=(50,120)   # Thresholds for Gradient Filtering\n",
    "color_thres=(120,255)# Thresholds for Color Filtering\n",
    "kernel=5\n",
    "\n",
    "ym_per_pix = None   #Y-axis image to meter conversion value\n",
    "xm_per_pix = None   #X-axis image to meter conversion value\n",
    "\n",
    "previous_left_fitx = []  # X axis pixels of previous left lane\n",
    "previous_right_fitx = [] # X axis pixels of previous Right lane\n",
    "\n",
    "previous_left_used_counter = 0  # counter to keep track of skipped left lanes\n",
    "previous_right_used_counter = 0 # counter to keep track of skipped right lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video data/output_videos/project_video_attempt2.mp4\n",
      "[MoviePy] Writing video data/output_videos/project_video_attempt2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [04:25<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: data/output_videos/project_video_attempt2.mp4 \n",
      "\n",
      "CPU times: user 5min 34s, sys: 1min 2s, total: 6min 37s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'data/output_videos/project_video_attempt2.mp4'\n",
    "clip1 = VideoFileClip(\"data/test_videos/project_video.mp4\")\n",
    "white_clip = clip1.fl_image(get_output_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
